{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from unidecode import unidecode\n",
    "#nltk.download('stopwords') \n",
    "stopwords.words('english')\n",
    "df = pd.read_csv(\"https://bit.ly/nlp-reuters\")\n",
    "corpus = df.content\n",
    "from nltk.tokenize import word_tokenize\n",
    "#bit.ly/nlp-reuters\n",
    "#tokens = word_tokenize(\"Tw Taiwan gives 400,000 masks to U.S. Taiwan under cooperation arrangement. #TaiwanCanHelp:)\")\n",
    "data=[word_tokenize(unidecode(docu))for docu in corpus ]\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "t=[]\n",
    "for i in range(len(data)):\n",
    "    ls=list(ngrams(data[i],2))\n",
    "    pos = pos_tag(data[i])\n",
    "    for i in range(len(ls)):\n",
    "        if pos[i][1]=='NNP' and pos[i+1][1]=='NNP':\n",
    "            t.append(ls[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('U.', 'S.'), 17601),\n",
       " (('Donald', 'Trump'), 3217),\n",
       " (('New', 'York'), 2443),\n",
       " (('Islamic', 'State'), 1925),\n",
       " (('President', 'Donald'), 1922)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "count=Counter(t)\n",
    "count.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "#!python -m spacy download en_core_web_lg\n",
    "df = pd.read_csv(\"http://bit.ly/nlp-buzzfeed\")\n",
    "contents = df.content\n",
    "titles = df.title\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60, 233, 488]\n"
     ]
    }
   ],
   "source": [
    "idx = [i for i, x in enumerate(df['content'].isna()) if x]\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = Counter()\n",
    "tokens=[]\n",
    "for i in range(len(contents)):\n",
    "    if i in idx:\n",
    "        continue\n",
    "    docu = nlp(contents[i])\n",
    "    tok=[]\n",
    "    for token in docu:\n",
    "        if token.is_stop !=True:\n",
    "            tok.append(token.lemma_+'_'+token.pos_)\n",
    "    tokens.append(tok)\n",
    "    vocabulary.update(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(vocabulary.most_common(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def tfidf_vectors(corpus, vocab):\n",
    "    def tfidf_vec(doc):\n",
    "        doc_freqs = Counter(doc)\n",
    "        return [doc_freqs[token] * math.log(N / df[token]) for token, _ in vocab]\n",
    "    df = Counter()\n",
    "    token_set = set([token for token, _ in vocab])\n",
    "    for document in corpus:\n",
    "        df.update(list(set(document) & token_set))\n",
    "        #print(df.most_common(10))\n",
    "    N = len(corpus)\n",
    "    # use df to compute the df-idf vector for each document\n",
    "    return [tfidf_vec(doc) for doc in corpus]\n",
    "tf_score = tfidf_vectors(tokens,vocabulary.most_common(512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec_a, vec_b):\n",
    "    assert len(vec_a) == len(vec_b)\n",
    "    a_b = sum(i[0] * i[1] for i in zip(vec_a, vec_b))\n",
    "    a_2 = sum([i*i for i in vec_a])\n",
    "    b_2 = sum([i*i for i in vec_b])\n",
    "    if a_2 == 0 or b_2 == 0:\n",
    "        return float('nan')\n",
    "    return a_b/(math.sqrt(a_2) * math.sqrt(b_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_similar(seed_id, vectors, k=5):\n",
    "    similarities = [cosine_similarity(vectors[seed_id], vectors[id]) for id in range(len(vectors))]\n",
    "    top_indices = sorted(range(len(similarities)), key=lambda i: similarities[i])[-k:] # https://stackoverflow.com/questions/13070461/get-indices-of-the-top-n-values-of-a-list\n",
    "    return [(id, similarities[id]) for id in reversed(top_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* This Woman Reimagined Michelangelo’s \"The Creation Of Adam\" With Black Women And It’s Beautiful\n",
      "  719 > This Woman Reimagined Michelangelo’s \"The Creation Of Adam\" With Black Women And It’s Beautiful (1.0000)\n",
      "  640 > Scientists Are Arguing About Whether The March For Science Will Be Too Political (0.6273)\n",
      "  625 > Trump Says Obamacare Will “Explode” After Replacement Fails In Congress (0.6133)\n",
      "  368 > Donald Trump Admits He Supported “Surgical” Intervention In Libya (0.5895)\n",
      "  820 > Latinos Are Expected To Vote In Droves But Major Liberal Efforts To Register Them Aren’t Off The Ground (0.5782)\n"
     ]
    }
   ],
   "source": [
    "seed_id = 719\n",
    "i=k_similar(seed_id , tf_score)\n",
    "print(\"* {}\".format(titles[seed_id]))\n",
    "for id, similarity in i:\n",
    "    print(\" {:4} > {} ({:.4f})\".format(id, titles[id], similarity))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
