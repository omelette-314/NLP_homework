{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "v_VCWeTO6bBS",
    "outputId": "c68ad6ca-9361-40bb-e5ae-857209744499"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 5354\n",
      "Dataset columns: Index(['title', 'content'], dtype='object')\n",
      "Int64Index([0], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def get_corpus():\n",
    "  df = pd.read_csv(\"https://raw.githubusercontent.com/bshmueli/108-nlp/master/reuters.csv\")\n",
    "  print(\"Dataset size:\",len(df))\n",
    "  print(\"Dataset columns:\",df.columns)\n",
    "  corpus=df['content'].to_list()\n",
    "  title = df['title'].to_list()\n",
    "  return corpus,title\n",
    "data,title=get_corpus()\n",
    "def get_stopword():\n",
    "  df = pd.read_csv(\"https://raw.githubusercontent.com/bshmueli/108-nlp/master/stopwords.txt\",header=None)\n",
    "  print(df.columns)\n",
    "  corpus= df[0].to_list()\n",
    "  return corpus\n",
    "stop_word = get_stopword()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jwwH6loE8rVZ"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "punc=list(set(string.punctuation))\n",
    "punc.append('\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "Pwn4bV1c8wIT",
    "outputId": "d19854e8-0abc-43f8-aa4e-aeeffdc2e4be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[':', '>', '#', ',', '&', \"'\", '}', '<', '~', '\"', '^', '!', '+', '\\\\', ';', '@', ']', '?', '`', '{', '(', '_', '/', '.', ')', '[', '-', '|', '$', '%', '=', '*', '\"']\n"
     ]
    }
   ],
   "source": [
    "print(punc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XwvFrWYNQZj-"
   },
   "source": [
    "### Clear Punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q3ys-uI69wMu"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def clear_punc(corpus,target_punc):\n",
    "  data=[]\n",
    "  for single_docu in corpus:\n",
    "    single_clear_docu=''\n",
    "    for element in single_docu:\n",
    "      for j in range(len(target_punc)):\n",
    "        if element == str(target_punc[j]):\n",
    "          element=None\n",
    "          break\n",
    "      if element!=None:  \n",
    "        single_clear_docu+= element\n",
    "    single_clear=re.sub(\"â€\".encode().decode(\"utf8\"), \"\".encode().decode(\"utf8\"),single_clear_docu.encode().decode(\"utf-8\"))\n",
    "    data.append(single_clear)\n",
    "  return data\n",
    "#clear_data=clear_punc(data[:10],punc)\n",
    "#print(data[0])\n",
    "#print(clear_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CiM6cyNyQdfr"
   },
   "source": [
    "### Convert to Lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kpiSlFZmAfqq"
   },
   "outputs": [],
   "source": [
    "def lower_(corpus):\n",
    "  corp=[]\n",
    "  for docx in corpus:\n",
    "    tmpstr=''\n",
    "    for word in docx:\n",
    "      if ord(word)>64 and ord(word)<91:\n",
    "        lower=chr(ord(word)+32)\n",
    "        tmpstr+=lower\n",
    "      else:\n",
    "        tmpstr+=word\n",
    "    corp.append(tmpstr)\n",
    "  return corp\n",
    "#lower_data=lower_(clear_data)\n",
    "#print(lower_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9F3uYMoyQlOL"
   },
   "source": [
    "### Remove_stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xMy1g34D8Iec"
   },
   "outputs": [],
   "source": [
    "def tokenize(document):\n",
    "  words = document.split(' ')\n",
    "  return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d6Jbj_9x7bbb"
   },
   "outputs": [],
   "source": [
    "stop_word.append('u')\n",
    "def clear_stop_word(corpus,target_stop_word):\n",
    "  corp=[]\n",
    "  for docx in corpus:\n",
    "    tokens=tokenize(docx)\n",
    "    tmp=[]\n",
    "    for token in tokens:\n",
    "      flag=0\n",
    "      for stop_word in target_stop_word:\n",
    "        if str(token) == str(stop_word) or token=='':\n",
    "          flag=1\n",
    "          break\n",
    "      if flag!=1:\n",
    "        tmp.append(token)\n",
    "    corp.append(tmp)\n",
    "  return corp\n",
    "#no_stop_corpus=clear_stop_word(lower_data,stop_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wJmvAi9v9ncW"
   },
   "outputs": [],
   "source": [
    "#print(no_stop_corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D-vpuE-wQrls"
   },
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d4x79eHG-Gq3"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def get_vocab(corpus):\n",
    "  vocabulary = Counter()\n",
    "  for document in corpus:\n",
    "    vocabulary.update(document)\n",
    "  return vocabulary\n",
    "#vocab=get_vocab(no_stop_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Im0n-rds96J5"
   },
   "outputs": [],
   "source": [
    "def tf(corpus):\n",
    "  tf_dict=[]\n",
    "  for docx in corpus:\n",
    "    docx_word_dict=Counter(docx)\n",
    "    tfdict=dict.fromkeys(docx_word_dict,0)\n",
    "    word_count=len(docx)\n",
    "    for word,count in docx_word_dict.items():\n",
    "      tfdict[word]=count / float(word_count)\n",
    "    tf_dict.append(tfdict)\n",
    "  return tf_dict\n",
    "#tf_score=tf(no_stop_corpus)\n",
    "#print(tf_score[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BFT5wv6aBCH4"
   },
   "outputs": [],
   "source": [
    "#print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHMhuRCxAQlo"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def idf(tf_scores,total_vocab):\n",
    "  idf_dict=[]\n",
    "  N=len(tf_scores)\n",
    "  idfdict = dict.fromkeys(total_vocab.keys(), 0)\n",
    "  for tf_score in tf_scores:\n",
    "    for word, val in tf_score.items():\n",
    "      #print(word,val)\n",
    "      if val > 0:\n",
    "        idfdict[word] += 1\n",
    "        #print(idfdict)\n",
    "  for word, val in idfdict.items():\n",
    "    idfdict[word] = math.log(N / float(val))\n",
    "  #print(idfdict)\n",
    "  return idfdict\n",
    "#idf_score=idf(tf_score,vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wz6z1yJ1EGWR"
   },
   "outputs": [],
   "source": [
    "#print(idf_score['hey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VIYCm26eEda1"
   },
   "outputs": [],
   "source": [
    "def tf_idf(tf,idf):\n",
    "  tf_idf_dict=[]\n",
    "  for docx_tf in tf:\n",
    "    tmp_dict={}\n",
    "    for word ,val in docx_tf.items():\n",
    "      tmp_dict[word]=val *idf[word]\n",
    "    tf_idf_dict.append(tmp_dict)\n",
    "  return tf_idf_dict\n",
    "#tf_idf_score=tf_idf(tf_score,idf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8XZ-EJnAFcGF"
   },
   "outputs": [],
   "source": [
    "#print(tf_idf_score[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "chV8_HAZQwof"
   },
   "source": [
    "### Get top 1000 per document tf-idf scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0DNmMrWcKxuJ"
   },
   "outputs": [],
   "source": [
    "def get_top(tf_corpus_dict,top=1000): \n",
    "  tops=[]\n",
    "  for tf_dict in tf_corpus_dict:\n",
    "    sorted_ = sorted(tf_dict.items(),reverse=True, key=lambda key: key[1])\n",
    "    keyList = [] \n",
    "    valueList = [] \n",
    "    i=0\n",
    "    for key,value in sorted_:\n",
    "      i+=1\n",
    "      keyList.append(key) \n",
    "      if i<top:\n",
    "        valueList.append(value) \n",
    "      else:\n",
    "        valueList.append(float(0))\n",
    "    top_tf_idf = dict(zip(keyList, valueList))\n",
    "    tops.append(top_tf_idf)\n",
    "  return tops\n",
    "#tf_idf_top_score=get_top(tf_idf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_V-93fDPVgq1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7SA-9jK7FyJL"
   },
   "outputs": [],
   "source": [
    "def doc2vec(i):\n",
    "  #words = tokenize(doc)\n",
    "  vec=[]\n",
    "  #print(i)  \n",
    "  for token ,_ in vocab.items():\n",
    "    #print(i,token)\n",
    "    if token in no_stop_corpus[i]:\n",
    "      vec.append(tf_idf_top_score[i][token])\n",
    "    else:\n",
    "      vec.append(float(0))\n",
    "  return vec\n",
    " # return [score if token in no_stop_corpus[i] else 0 for token,score in tf_idf_top_score[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KDrIELEhFxLl"
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(vec_a,vec_b):\n",
    "  assert len(vec_a) == len(vec_b)\n",
    "  if (sum(vec_a) == 0 or sum(vec_b)==0):\n",
    "    return 0\n",
    "  a_b=sum(i[0] * i[1] for i in zip(vec_a,vec_b))\n",
    "  a_2=sum(i*i for i in vec_a)\n",
    "  b_2=sum(i*i for i in vec_b)\n",
    "  return a_b/(math.sqrt(a_2)*math.sqrt(b_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MUwR3q2hRLap"
   },
   "outputs": [],
   "source": [
    "def doc_similarity(doc_a,doc_b):\n",
    "  return cosine_similarity(doc2vec(doc_a),doc2vec(doc_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EPgn_HIRRU_6"
   },
   "outputs": [],
   "source": [
    "def k_similar(seed_id, k=5):\n",
    "  seed_doc = title[seed_id]\n",
    "  print('> \"{}\"'.format(seed_doc))\n",
    "  similarities = [doc_similarity(seed_id,doc) for doc in range(len(data))]\n",
    "  top_indices = sorted(range(len(similarities)),key = lambda i : similarities[i])[-k:]\n",
    "  nearest = [[title[id],similarities[id]] for id in top_indices]\n",
    "  for story in reversed(nearest):\n",
    "    print('*\"{}\"({})'.format(story[0],story[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "QByeesi1Ttoi",
    "outputId": "9d975133-83bc-4264-edaa-a5fa97814252"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \"Oil slips, inventories curb recovery from four-month lows\"\n",
      "*\"Oil slips, inventories curb recovery from four-month lows\"(1.0000000000000002)\n",
      "*\"Oil drops to lowest since November as U.S. inventories swell\"(0.6067763300105031)\n",
      "*\"Oil jumps over 10 percent as OPEC finalizes output cut deal\"(0.49123403216885536)\n",
      "*\"Oil falls on output cut skepticism, OPEC and Russia output rise\"(0.45928501328511667)\n",
      "*\"Oil falls $2 a barrel on OPEC cut uncertainty ahead of meeting\"(0.45830258845520333)\n"
     ]
    }
   ],
   "source": [
    "clear_data=clear_punc(data,punc)\n",
    "lower_data=lower_(clear_data)\n",
    "no_stop_corpus=clear_stop_word(lower_data,stop_word)\n",
    "vocab=dict(get_vocab(no_stop_corpus))\n",
    "tf_score=tf(no_stop_corpus)\n",
    "idf_score=idf(tf_score,vocab)\n",
    "tf_idf_score=tf_idf(tf_score,idf_score)\n",
    "tf_idf_top_score=get_top(tf_idf_score)\n",
    "k_similar(719)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xpguXonwpr_N"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "print(doc_similarity(719,719))\n",
    "#print(doc2vec(0))\n",
    "> \"Oil slips, inventories curb recovery from four-month lows\"\n",
    "*\"Oil slips, inventories curb recovery from four-month lows\"(1.0000000000000002)\n",
    "*\"Oil drops to lowest since November as U.S. inventories swell\"(0.6067763300105031)\n",
    "*\"Oil jumps over 10 percent as OPEC finalizes output cut deal\"(0.49123403216885536)\n",
    "*\"Oil falls on output cut skepticism, OPEC and Russia output rise\"(0.45928501328511667)\n",
    "*\"Oil falls $2 a barrel on OPEC cut uncertainty ahead of meeting\"(0.45830258845520333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iDf0oB_0ptFc"
   },
   "outputs": [],
   "source": [
    "#print(no_stop_corpus[0])\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP hw.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
